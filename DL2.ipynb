{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Các cấu trúc phổ biến của mạng CNN](https://forum.machinelearningcoban.com/t/kien-truc-cac-mang-cnn-noi-tieng-phan-1-alex-lenet-inception-vgg/2582)\n",
    "\n",
    "[Qua trinh phat trien NN](https://dlapplications.github.io/2018-07-06-CNN/)\n",
    "\n",
    "<img src=\"Mathematic-NN/image/cnn1.jpg\" width=400 height = 400>\n",
    "\n",
    "Convolutional neural network là một mạng neural được ứng dụng rất nhiều trong deep learning trong computer vision cho classifier và localizer . \n",
    "Từ mạng CNN cơ bản người ta có thể tạo ra rất nhiều architect khác nhau, từ những mạng neural cơ bản 1 đến 2 layer đến 100 layer. \n",
    "Đã bao giờ bạn tự hỏi:\n",
    "   - nên sử dụng bao nhiêu layer, nên kết hợp conv với maxpooling thế nào? \n",
    "   - conv-maxpooling hay conv-conv-maxplooling ? \n",
    "   - hay nên sử dụng kernel 3x3 hay 5x5 thậm chí 7x7 điểm khác biệt là gì ? \n",
    "   - Làm gì khi model bị vanishing/exploding gradient, hay tại sao thi thêm nhiều layer hơn thì theo lý thuyết accuarcy phải cao hơn so với shallow model, nhưng thực tế lại không phải accuarcy không tăng thậm chí là giảm đó có phải nguyên nhân do overfitting.\n",
    "Việc tìm hiểu các architure nổi tiếng để xem cấu trúc của nó như thế nào, các ý tưởng về CNN mới nhất hiện nay, từ đó ta có thể trả lời được mấy câu hỏi trên. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://dlapplications.github.io/2018-07-06-CNN/\" width=\"1000\" height=\"600\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://dlapplications.github.io/2018-07-06-CNN/\" width=\"1000\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **LeNet(1998)** \n",
    "    - Cấu trúc của LeNet gồm 2 layer (Convolution + maxpooling) và 2 layer fully connected layer và output là softmax layer \n",
    "    - Softmax layer, output = 10 (train với mnist nên 10 digits). Nhược điểm của LeNet là mạng còn rất đơn giản và sử dụng sigmoid (or tanh) ở mỗi convolution layer mạng tính toán rất chậm.\n",
    "- **Alexnet(2012)**\n",
    "    - Sử dụng relu thay cho sigmoid(or tanh) để xử lý với non-linearity. Tăng tốc độ tính toán lên 6 lần.\n",
    "    - Sử dụng dropout như một phương pháp regularization mới cho CNN. Dropout không những giúp mô hình tránh được overfitting mà còn làm giảm thời gian huấn luyện mô hình\n",
    "    - Overlap pooling để giảm size của network ( Traditionally pooling regions không overlap).\n",
    "    - Sử dụng local response normalization để chuẩn hóa ở mỗi layer.\n",
    "    - Sử dụng kỹ thuật data augmentation để tạo them data training bằng cách translations, horizontal reflections.\n",
    "- **ZFnet(2013)**\n",
    "    - Tương tự AlexNet nhưng có một số điều chỉnh nhỏ.\n",
    "    - Alexnet training trên 15m image trong khi ZF training chỉ có 1.3m image.\n",
    "    - Sử dụng kernel 7x7 ở first layer (alexnet 11x11).Lý do là sử dụng kernel nhỏ hơn để giữ lại nhiều thông tin trên image hơn.\n",
    "    - Tăng số lượng filter nhiều hơn so với alexnet\n",
    "- **VGGnet(2014)**\n",
    "    - VGG thì sử dụng 1 chuỗi Conv liên tiếp Conv-Conv-Conv ở middle và end của architect VGG. Việc này sẽ làm cho việc tính toán trở nên lâu hơn nhưng những feature sẽ vẫn được giữ lại nhiều hơn so với việc sử dụng maxpooling sau mỗi Conv (được hỗ trợ bởi GPU)\n",
    "    - Architect của VGG16 bao gồm 16 layer :13 layer Conv (2 layer conv-conv,3 layer conv-conv-conv) đều có kernel 3x3, sau mỗi layer conv là maxpooling downsize xuống 0.5, và 3 layer fully connection. \n",
    "    - VGG19 tương tự như VGG16 nhưng có thêm 3 layer convolution ở 3 layer conv cuối ( thành 4 conv stack với nhau).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google\n",
    "- **GoogleNet(2014) - Inception module NN**\n",
    "    - chỉ có 5m tham số so với alexnet là 60m nhanh hơn gấp 12 lần \n",
    "    - ý tưởng của *Inception module*, nó tính toán các kernel size khác nhau, và pooling từ một input sau đó concatenate nó lại thành output. <img src=\"Mathematic-NN/image/cnn5.jpg\" width=400 height = 400>    \n",
    "       - Trong inception người ta dùng conv kernel 1x1 với 2 mục đích là giảm tham số tính toán và dimensionality reduction . Dimensionality reduction có thể hiểu làm giảm depth của input (vd iput 28x28x100 qua kernel 1x1 với filter = 10 sẽ giảm depth về còn 28x28x10)\n",
    "       - Inception v1: có 2 dạng là naïve và dimension reduction. Khác biệt chính đó là version dimension reduction nó dùng conv 1x1 ở mỗi layer để giảm depth của input giúp model có ít tham số hơn. Inception naïve có architect gồm 1x1 conv,3x3 conv, 5x5 conv và 3x3 maxpooling. \n",
    "       - Inception v2 : Cải thiện version 1, thêm layer batchnormalize và giảm Internal Covariate Shift. Ouput của mỗi layer sẽ được normalize về Gaussian N(0,1). Conv 5x5 sẽ được thay thế bằng 2 conv 3x3 để giảm computation cost. \n",
    "       - Inception v3: Điểm đáng chú ý ở version này là Factorization. Conv 7x7 sẽ được giảm về conv 1 dimesion là (1x7),(7x1). Tương tự conv 3x3 (3x1,1x3). Tăng tốc độ tính toán. Khi tách ra 2 conv thì làm model deeper hơn. \n",
    "       - Inception v4 : là sự kết hợp inception và resnet.\n",
    "    - GoogleNet gồm 22 layer, khởi đầu vẫn là những simple convolution layer, tiếp theo là những block của inception module với maxpooling theo sau mỗi block. Một số đặc điểm chính.\n",
    "    - Sử dụng 9 Inception module trên toàn bộ architect. Làm model deeper hơn rất nhiều.\n",
    "    - Không sử dụng fully connection layer mà thay vào đó là average pooling từ 7x7x1024 volume thành 1x1x1024 volume giảm thiểu được rất nhiều parameter.\n",
    "- **ResNets(2015)**    \n",
    "    - Để hiểu ResNet chúng ta cần hiểu vấn đề khi stack nhiều layer khi training, vấn đề đầu tiên khi tăng model deeper hơn gradient sẽ bị vanishing/explodes. \n",
    "    - Vấn đề này có thể giải quyết bằng cách thêm Batch Normalization nó giúp normalize output giúp các hệ số trở nên cân bằng hơn không quá nhỏ hoặc quá lớn nên sẽ giúp model dễ hội tụ hơn. Vấn đề thứ 2 là degradation, Khi model deeper accuracy bắt đầu bão hòa(saturated) thậm chí là giảm. Resnet được ra đời để giải quyết vấn đề degradation này. \n",
    "    - ResNet có architecture gồm nhiều residual block, ý tưởng chính là skip layer bằng cách add connection với layer trước. Ý tưởng của residual block là feed foword x(input) qua một số layer conv-max-conv, ta thu được F(x) sau đó add thêm x vào H(x) = F(x) + x . Model sẽ dễ học hơn khi chúng ta thêm feature từ layer trước vào. \n",
    "    - <img src=\"Mathematic-NN/image/cnn12.jpg\" width=400 height = 400>   \n",
    "- **Densenet(2016)**     \n",
    "    - Gần giống Resnet nhưng có một vài điểm khác biệt. Densenet có cấu trúc gồm các dense block và các transition layers. \n",
    "    - Được stack như (dense block) - (transition layers) - (dense block) - (transition layers) \n",
    "    - Ở mỗi dense block sẽ có normalization, nonlinearity và dropout. Để giảm size và depth của feature thì transition layer được đặt giữa các dense block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Yolo](https://forum.machinelearningcoban.com/t/yolo-tutorial-cung-code-lai-yolo2/3859)\n",
    "- [RetinaNet](https://towardsdatascience.com/review-retinanet-focal-loss-object-detection-38fba6afabe4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resources:\n",
    "- [nttuan-dlcoban-tranfer learning](https://nttuan8.com/bai-9-transfer-learning-va-data-augmentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 2 loại transfer learning:\n",
    "   - Feature extractor: Sau khi lấy ra các đặc điểm (features) của ảnh bằng việc sử dụng ConvNet của pre-trained model, thì ta sẽ dùng linear classifier (linear SVM, softmax classifier,..) để phân loại ảnh. \n",
    "       - Có thể sử dụng softmax regression để phân biệt multiclass, hay sử dụng nhiều lần logistic regression\n",
    "   - Fine tuning: Sau khi lấy ra các đặc điểm của ảnh bằng việc sử dụng ConvNet của pre-trained model, thì ta sẽ coi đây là input của 1 CNN mới bằng cách thêm vào 1 top-block mới là các ConvNet và Fully Connected layer. \n",
    "       - B1: đóng bằng phần ConvNet của pretrained model, chỉ train trên phần top-block mới\n",
    "       - B2: xả băng toàn phần hoặc 1 phần cần thiết để train cùng với top-block mới\n",
    "       \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi nào nên dùng **transfer learning**\n",
    "\n",
    "Có 2 yếu tố quan trọng nhất để dùng transfer learning đó là kích thước của dữ liệu bạn có và sự tương đồng của dữ liệu giữa mô hình bạn cần train và pre-trained model.\n",
    "\n",
    "- Dữ liệu bạn có nhỏ và tương tự với dữ liệu ở pre-trained model. Vì dữ liệu nhỏ nên nếu dùng fine-tuning thì model sẽ bị overfitting. Hơn nữa là dữ liệu tương tự nhau nên là ConvNet của pre-trained model cũng lấy ra các đặc điểm ở dữ liệu của chúng ta. Do đó nên dùng feature extractor.\n",
    "- Dữ liệu bạn có lớn và tương tự với dữ liệu ở pre-trained model. Giờ có nhiều dữ liệu ta không sợ overfitting do đó nên dùng fine-tuning.\n",
    "- Dữ liệu bạn có nhỏ nhưng khác với dữ liệu ở pre-trained model. Vì dữ liệu nhỏ nên ta lên dùng feature extractor để tránh overfitting. Tuy nhiên do dữ liệu ta có và dữ liệu ở pre-trained model khác nhau, nên không nên dùng feature extractor với toàn bộ ConvNet của pre-trained model mà chỉ dùng các layer đầu. Lý do là vì các layer ở phía trước sẽ học các đặc điểm chung chung hơn (cạnh, góc,…), còn các layer phía sau trong ConvNet sẽ học các đặc điểm cụ thể hơn trong dataset (ví dụ mắt, mũi,..).\n",
    "- Dữ liệu bạn có lớn và khác với dữ liệu ở pre-trained model. Ta có thể train model từ đầu, tuy nhiên sẽ tốt hơn nếu ta khởi tạo các giá trị weight của model với giá trị của pre-trained model và sau đó train bình thường.\n",
    "\n",
    "Lưu ý:\n",
    "- Vì pre-trained model đã được train với kích thước ảnh cố định, nên khi dùng pre-trained model ta cần resize lại ảnh có kích ảnh bằng kích thước mà ConvNet của pre-trained model yêu cầu.\n",
    "- Hệ số learning rate của ConvNet của pre-trained model nên được đặt với giá trị nhỏ vì nó đã được học ở pre-trained model nên ít cần cập nhật hơn so với các layer mới thêm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Các kỹ thuật phụ trợ trong DL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. from nttd\n",
    "Nội dung\n",
    "\n",
    "    Vectorization\n",
    "    Mini-batch gradient descent\n",
    "        Mini-batch gradient descent là gì\n",
    "        Các thông số trong bini-batch gradient descent\n",
    "    Bias và variance\n",
    "        Bias, variance là gì\n",
    "        Bias, variance tradeoff\n",
    "        Đánh giá bias and variance\n",
    "    Dropout\n",
    "        Dropout là gì\n",
    "        Dropout hạn chế việc overfitting\n",
    "        Lời khuyên khi dùng dropout\n",
    "    Activation function\n",
    "        Non-linear activation function\n",
    "        Vanishing và exploding gradient\n",
    "        Một số activation thông dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://nttuan8.com/bai-10-cac-ky-thuat-co-ban-trong-deep-learning/\" width=\"1000\" height=\"600\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://nttuan8.com/bai-10-cac-ky-thuat-co-ban-trong-deep-learning/\" width=\"1000\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [weight-initialization-techniques-in-neural-networks](https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
