{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANFER LEARNING\n",
    "**Table of contents**\n",
    "- [Technical Notes](#note)\n",
    "- [Pretrained Model](#pretrained-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Topic tranfer learning ở trong các sách](https://www.sciencedirect.com/topics/engineering/transfer-learning)\n",
    "\n",
    "Resources:\n",
    "- [tổng hợp về transfer learning](https://forum.machinelearningcoban.com/t/tong-hop-transfer-learning/5388)\n",
    "- [nttuan-dlcoban-tranfer learning](https://nttuan8.com/bai-9-transfer-learning-va-data-augmentation/)\n",
    "- [A Comprehensive Hands-on Guide to Transfer Learning with Real-World Applications in Deep Learning](https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a)\n",
    "- [Transfer learning: the dos and don’ts](https://medium.com/starschema-blog/transfer-learning-the-dos-and-donts-165729d66625)\n",
    "- [Approach pre-trained deep learning models with caution](https://medium.com/comet-ml/approach-pre-trained-deep-learning-models-with-caution-9f0ff739010c)\n",
    "- https://dlapplications.github.io/2018-07-15-Transfer-Learning-Basic/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://nttuan8.com/bai-9-transfer-learning-va-data-augmentation/\" width=\"1000\" height=\"600\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://nttuan8.com/bai-9-transfer-learning-va-data-augmentation/\" width=\"1000\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Có 2 loại transfer learning:\n",
    "   - Feature extractor: Sau khi lấy ra các đặc điểm (features) của ảnh bằng việc sử dụng ConvNet của pre-trained model, thì ta sẽ dùng linear classifier (linear SVM, softmax classifier,..) để phân loại ảnh. \n",
    "       - Có thể sử dụng softmax regression để phân biệt multiclass, hay sử dụng nhiều lần logistic regression\n",
    "   - Fine tuning: Sau khi lấy ra các đặc điểm của ảnh bằng việc sử dụng ConvNet của pre-trained model, thì ta sẽ coi đây là input của 1 CNN mới bằng cách thêm vào 1 top-block mới là các ConvNet và Fully Connected layer. \n",
    "       - B1: đóng bằng phần ConvNet của pretrained model, chỉ train trên phần top-block mới\n",
    "       - B2: xả băng toàn phần hoặc 1 phần cần thiết để train cùng với top-block mới\n",
    "       \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Khi nào nên dùng **transfer learning**\n",
    "\n",
    "Có 2 yếu tố quan trọng nhất để dùng transfer learning đó là kích thước của dữ liệu bạn có và sự tương đồng của dữ liệu giữa mô hình bạn cần train và pre-trained model.\n",
    "\n",
    "- Dữ liệu bạn có nhỏ và tương tự với dữ liệu ở pre-trained model. Vì dữ liệu nhỏ nên nếu dùng fine-tuning thì model sẽ bị overfitting. Hơn nữa là dữ liệu tương tự nhau nên là ConvNet của pre-trained model cũng lấy ra các đặc điểm ở dữ liệu của chúng ta. Do đó nên dùng feature extractor.\n",
    "- Dữ liệu bạn có lớn và tương tự với dữ liệu ở pre-trained model. Giờ có nhiều dữ liệu ta không sợ overfitting do đó nên dùng fine-tuning.\n",
    "- Dữ liệu bạn có nhỏ nhưng khác với dữ liệu ở pre-trained model. Vì dữ liệu nhỏ nên ta lên dùng feature extractor để tránh overfitting. Tuy nhiên do dữ liệu ta có và dữ liệu ở pre-trained model khác nhau, nên không nên dùng feature extractor với toàn bộ ConvNet của pre-trained model mà chỉ dùng các layer đầu. Lý do là vì các layer ở phía trước sẽ học các đặc điểm chung chung hơn (cạnh, góc,…), còn các layer phía sau trong ConvNet sẽ học các đặc điểm cụ thể hơn trong dataset (ví dụ mắt, mũi,..).\n",
    "- Dữ liệu bạn có lớn và khác với dữ liệu ở pre-trained model. Ta có thể train model từ đầu, tuy nhiên sẽ tốt hơn nếu ta khởi tạo các giá trị weight của model với giá trị của pre-trained model và sau đó train bình thường.\n",
    "\n",
    "Lưu ý:\n",
    "- Vì pre-trained model đã được train với kích thước ảnh cố định, nên khi dùng pre-trained model ta cần resize lại ảnh có kích ảnh bằng kích thước mà ConvNet của pre-trained model yêu cầu.\n",
    "- Hệ số learning rate của ConvNet của pre-trained model nên được đặt với giá trị nhỏ vì nó đã được học ở pre-trained model nên ít cần cập nhật hơn so với các layer mới thêm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"note\"></a>\n",
    "# TECHNICAL NOTE- Các kỹ thuật phụ trợ trong DL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Argumentation là gì?\n",
    "- https://nttuan8.com/bai-9-transfer-learning-va-data-augmentation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Như các bạn đã biết, một bài toán về Deep Learning đòi hỏi một lượng lớn về dữ liệu và không phải trong thực tế lúc nào cũng có đầy đủ lượng dữ liệu cho chúng ta. Thế nên việc làm phoing phú dữ liệu là một việc làm cần thiết. Thuật ngữ đó được gọi là Data augmentation. Data augmentation giúp chúng ta tăng kích thước của tập dữ liệu lên nhanh chóng đồng thời thay đổi, thêm mới các tính chất vào trong dữ liệu hiện tại giúp cho độ phong phú của dữ liệu trở nên dồi dào hơn. Kĩ thuật này đặc biệt hữu ích khi các tập dữ liệu của chúng ta là nhỏ. Sau đây chúng ta sẽ tìm hiểu một vài kĩ thuật trong số đó áp dụng cho dữ liệu dạng hình ảnh (image).\n",
    "- Flipping : lật ảnh theo chiều dọc hay theo chiều ngang\n",
    "- Random Cropping - cắt ra ngẫu nhiên một thành phần trong hình ảnh gốc để làm dữ liệu mới\n",
    "- Shearing - thay đổi góc nhìn của hình ảnh, hình dạng của hình ảnh thông qua các giải thuật transform\n",
    "- Rotation: xoay ảnh theo một góc nào đó\n",
    "- Whitening: chỉ giữ lại các thành phần quan trọng trong ảnh thông qua giải thuật Principal Component Analysis\n",
    "- Normalization - là một phương pháp chuẩn hóa hình ảnh theo giá trị trung bình và độ lệch chuẩn\n",
    "- Channel shifting: thay đổi các kênh màu làm cho mô hình dễ dàng học được các đặc trưng từ ảnh hơn\n",
    "\n",
    "Đối với Keras các bạn có thể tìm thấy tất cả các kĩ thuật này ở trong thư viện ImageDataGenerator. Chúng ta có thể sử dụng đoạn code sau để load dữ liệu với việc augmentation ảnh .\n",
    "```python\n",
    "    generator_train = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.3,\n",
    "    shear_range=0.3,)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Các Note cho NN\n",
    "Nội dung\n",
    "\n",
    "    Vectorization\n",
    "    Mini-batch gradient descent\n",
    "        Mini-batch gradient descent là gì\n",
    "        Các thông số trong bini-batch gradient descent\n",
    "    Bias và variance\n",
    "        Bias, variance là gì\n",
    "        Bias, variance tradeoff\n",
    "        Đánh giá bias and variance\n",
    "    Dropout\n",
    "        Dropout là gì\n",
    "        Dropout hạn chế việc overfitting\n",
    "        Lời khuyên khi dùng dropout\n",
    "    Activation function\n",
    "        Non-linear activation function\n",
    "        Vanishing và exploding gradient\n",
    "        Một số activation thông dụng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://nttuan8.com/bai-10-cac-ky-thuat-co-ban-trong-deep-learning/\" width=\"1000\" height=\"600\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://nttuan8.com/bai-10-cac-ky-thuat-co-ban-trong-deep-learning/\" width=\"1000\" height=\"600\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Làm sao để chọn initial weight cho NN?\n",
    "- [weight-initialization-techniques-in-neural-networks](https://towardsdatascience.com/weight-initialization-techniques-in-neural-networks-26c649eb3b78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pretrained-model\"></a>\n",
    "# PRETRAINED MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch-vision được train trên ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/@14prakash/almost-any-image-classification-problem-using-pytorch-i-am-in-love-with-pytorch-26c7aa979ec4\n",
    "\n",
    "Key note:\n",
    "```python\n",
    "## Load the model \n",
    "model_conv = torchvision.models.inception_v3(pretrained='imagenet')\n",
    "\n",
    "## Lets freeze the first few layers. This is done in two stages \n",
    "# Stage-1 Freezing all the layers \n",
    "if freeze_layers:\n",
    "  for i, param in model_conv.named_parameters():\n",
    "    param.requires_grad = False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "- [avaialble pretrained model of keras on Imagenet](https://keras.io/applications/#models-for-image-classification-with-weights-trained-on-imagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sử dụng retrained của keras\n",
    "- https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8\n",
    "- https://www.learnopencv.com/keras-tutorial-using-pre-trained-imagenet-models/\n",
    "- https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751\n",
    "- https://viblo.asia/p/handbook-cv-with-dl-phan-3-bai-toan-phan-loai-hinh-anh-image-classification-voi-keras-bJzKmymXK9N\n",
    "\n",
    "key note:\n",
    "```python\n",
    "## Load the model\n",
    "model = applications.VGG19(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:5]:\n",
    "    layer.trainable = False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tensorflow Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tensorflow keras, tranfer learning - fine tune, mobilenetV2](https://www.tensorflow.org/tutorials/images/transfer_learning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
