{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OBVQntKmkBDw"
   },
   "source": [
    "# **Tutourial**\n",
    "\n",
    "\n",
    "DL : ly thuyet va code\n",
    "- https://github.com/mbadry1/DeepLearning.ai-Summary\n",
    "- [note-deeplearningai](https://www.analyticsvidhya.com/blog/2018/10/introduction-neural-networks-deep-learning/)\n",
    "- [cheat-sheat](https://ml-cheatsheet.readthedocs.io/en/latest/layers.html#lstm)\n",
    "\n",
    "Blog:\n",
    "- [MIT-Lex Fridman](https://medium.com/tensorflow/mit-deep-learning-basics-introduction-and-overview-with-tensorflow-355bcd26baf0)\n",
    "- [ongxuanhong-DL](https://ongxuanhong.wordpress.com/category/data-science/deep-learning/)\n",
    "- [https://dlapplications.github.io/]\n",
    "- [https://nttuan8.com/]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRSO8KKkHbxA"
   },
   "source": [
    "# Table of content\n",
    "1. [Multi-Perceptron](#multi-perceptron)\n",
    "2. [CNN](#CNN)\n",
    "\n",
    "- [Transfer Learning](#transferlearning)\n",
    "- [Validation of Neural Network](#validation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dVNXFhf2_B7"
   },
   "source": [
    "<a id=\"multi-perceptron\"></a>\n",
    "# 1. Multi-Perceptron\n",
    "\n",
    "Resources:\n",
    "[softmax,cross-entropy](https://machinelearningcoban.com/2017/02/17/softmax/#-cross-entropy)\n",
    "- [Perceptron](https://dlapplications.github.io/2018-06-11-perceptron/)\n",
    "- [Multi-perceptron](https://dlapplications.github.io/2018-06-15-MLP/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dFUr3XT-2-4E"
   },
   "source": [
    "## Feedforward & Backpropagation\n",
    "\n",
    "A\n",
    "\n",
    "Sources:\n",
    "\n",
    "   - [1, nguyen huu tiep](https://machinelearningcoban.com/2017/02/24/mlp/)\n",
    "   - [2, nttuan](https://nttuan8.com/bai-4-backpropagation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYmdWybCIHKc"
   },
   "source": [
    "## Fully connected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1bwPIlsJDvE"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhes7yDS-F5H"
   },
   "source": [
    "<a id=\"CNN\"></a>\n",
    "# 2. Convolution Neural Network\n",
    "\n",
    "- [understand](https://topdev.vn/blog/thuat-toan-cnn-convolutional-neural-network/)\n",
    "- [https://nttuan8.com/bai-6-convolutional-neural-network/]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JTYoH2vxCfM8"
   },
   "source": [
    "<a id=\"validation\"></a>\n",
    "# Validation\n",
    "\n",
    "## Overfitting\n",
    "- [dropout and noise layer](https://medium.com/@maksutov.rn/deep-study-of-a-not-very-deep-neural-network-part-5-dropout-and-noise-29d980ece933)\n",
    "- có để thực hiện CNN với kernel 1x1x3 -> hoạt động giống relularzization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kyj4umHkdAg8"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_91auMEHhV6"
   },
   "source": [
    "# Code - Tf/Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xrrSMqQT2_Ed"
   },
   "source": [
    "## Active function\n",
    "- [ML-Regression](https://colab.research.google.com/drive/15RAbgNf-2Lkv_TOjgYtDafWvy3vASbzy#scrollTo=IDHLmr9DPmak)\n",
    "- https://aivietnam.ai/courses/aisummer2019/lessons/ham-activations/\n",
    "- [Tf-keras activation](https://www.tensorflow.org/api_docs/python/tf/keras/activations), [keras](https://keras.io/activations/), [more-explain](https://ml-cheatsheet.readthedocs.io/en/latest/activation_functions.html)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jjNhjU1IAp7V"
   },
   "source": [
    "**Choosing the right Activation Function**\n",
    "\n",
    "Now that we have seen so many activation  functions, we need some logic / heuristics to know which activation function should be used in which situation. Good or bad – there is no rule of thumb.\n",
    "\n",
    "However depending upon the properties of the problem we might be able to make a better choice for easy and quicker convergence of the network.\n",
    "\n",
    "*  **Sigmoid** functions and their combinations generally work better in the case of classifiers\n",
    "*  **Sigmoids and tanh** functions are sometimes avoided due to the vanishing gradient problem\n",
    "*  **ReLU** function is a general activation function and is used in most cases these days\n",
    "*  If we encounter a case of dead neurons in our networks the leaky **ReLU** function is the best choice\n",
    "*  Always keep in mind that **ReLU** function should only be used in the hidden layers\n",
    "*  As a rule of thumb, you can begin with using **ReLU** function and then move over to other activation functions in case **ReLU** doesn’t provide with optimum results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vljP43l2tsWh"
   },
   "source": [
    "## Layers\n",
    "\n",
    "Source [tf-layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iSQHglhXLzjx"
   },
   "source": [
    "**Core layers**\n",
    "\n",
    "- **Dropout**\n",
    "  - [understand](https://www.phamduytung.com/blog/2019-05-05-deep-learning-dropout/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RvWgqmoQMGvm"
   },
   "source": [
    "**Convolutional  & Pooling & Connected Layers**\n",
    "[theory](https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53)\n",
    "\n",
    "**Convolutional Layers**\n",
    "- The role of the ConvNet is to reduce the images into a form which is easier to process, without losing features which are critical for getting a good prediction. \n",
    "\n",
    "Source: [keras-convol](https://keras.io/layers/convolutional/),\n",
    "\n",
    "\n",
    "**Pooling Layer**\n",
    "\n",
    "The Pooling layer is responsible for reducing the spatial size of the Convolved Feature. \n",
    "- This is to decrease the computational power required to process the data through dimensionality reduction. \n",
    "- Furthermore, it is useful for extracting dominant features which are rotational and positional invariant, thus maintaining the process of effectively training of the model.\n",
    "\n",
    "Source: [keras-pooling](https://keras.io/layers/pooling/)\n",
    "\n",
    "**Connected Layer**\n",
    "[understand1](https://pennlio.wordpress.com/2014/04/11/fully-connected-locally-connected-and-shared-weights-layer-in-neural-networks/), [understand-2](https://prateekvjoshi.com/2016/04/12/understanding-locally-connected-layers-in-convolutional-neural-networks/)\n",
    "\n",
    "Connected layer is a (usually) cheap way of learning non-linear combinations of the high-level features as represented by the output of the convolutional layer\n",
    "- Densly\n",
    "- Fully\n",
    "- Locally\n",
    "\n",
    "Source: [keras-connected](https://keras.io/layers/local/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xNH4-iqpmT4"
   },
   "source": [
    "**Embedding & Merge Layers**\n",
    "[understand](https://medium.com/@satnalikamayank12/on-learning-embeddings-for-categorical-data-using-keras-165ff2773fc9)\n",
    "Source: [keraas-embed](https://keras.io/layers/embeddings/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kEQh8u6p5w2"
   },
   "source": [
    "**Normalization Layers**\n",
    "\n",
    "[understand](https://forum.machinelearningcoban.com/t/correct-me-if-i-am-wrong-batch-normalize/2561)\n",
    "\n",
    "\n",
    "Source: [Batch-norm](https://keras.io/layers/normalization/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VelRQ0AUMpjE"
   },
   "source": [
    "**Recurrent Layers - RNN**\n",
    "\n",
    "\n",
    "Source: [keras-RN](https://keras.io/layers/recurrent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yY7oooODCt5J"
   },
   "source": [
    "**Noise Layer**\n",
    "\n",
    "[understand](https://towardsdatascience.com/how-to-use-noise-to-your-advantage-5301071d9dc3)\n",
    "\n",
    "source: [keras-noise](https://keras.io/layers/noise/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vfe-ZpIwKLST"
   },
   "source": [
    "# Transfer Learning\n",
    "\n",
    "[understand](https://dlapplications.github.io/2018-07-15-Transfer-Learning-Basic/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dfnHjfRK-G_D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPbU5I5_2-eU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rbczoGOz22o7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2.DL.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
